# Projet IA GÃ©nÃ©rative - GÃ©nÃ©ration d'Art avec GANs

## ğŸ“‹ Description

Ce projet implÃ©mente un systÃ¨me complet de gÃ©nÃ©ration d'art utilisant des rÃ©seaux antagonistes gÃ©nÃ©ratifs (GANs). Il comprend plusieurs architectures de GANs (DCGAN, CycleGAN) pour gÃ©nÃ©rer des Å“uvres d'art dans diffÃ©rents styles, ainsi qu'une API REST pour servir les modÃ¨les entraÃ®nÃ©s.

## ğŸ¯ Objectifs

- **GÃ©nÃ©ration d'art** : CrÃ©er des Å“uvres d'art originales dans diffÃ©rents styles
- **Transfert de style** : Transformer des images existantes selon diffÃ©rents styles artistiques
- **API de production** : Servir les modÃ¨les via une API REST performante
- **Interface utilisateur** : Fournir une interface web pour interagir avec les modÃ¨les

## ğŸ—ï¸ Architecture

```
Projet 8 IA GÃ©nÃ©rative/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # Configuration du projet
â”‚   â”œâ”€â”€ data/                  # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py         # Classes de dataset
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # PrÃ©processing des images
â”‚   â”‚   â””â”€â”€ analysis.py        # Analyse du dataset
â”‚   â”œâ”€â”€ models/                # ModÃ¨les GAN
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_gan.py        # Classe de base
â”‚   â”‚   â”œâ”€â”€ dcgan.py           # DCGAN
â”‚   â”‚   â”œâ”€â”€ cyclegan.py        # CycleGAN
â”‚   â”‚   â”œâ”€â”€ losses.py          # Fonctions de perte
â”‚   â”‚   â””â”€â”€ utils.py           # Utilitaires
â”‚   â”œâ”€â”€ training/              # EntraÃ®nement
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py         # Classes d'entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ callbacks.py       # Callbacks d'entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ metrics.py         # MÃ©triques d'Ã©valuation
â”‚   â”‚   â””â”€â”€ utils.py           # Utilitaires d'entraÃ®nement
â”‚   â””â”€â”€ api/                   # API REST
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ app.py             # Application FastAPI
â”‚       â”œâ”€â”€ models.py          # ModÃ¨les Pydantic
â”‚       â””â”€â”€ utils.py           # Utilitaires API
â”œâ”€â”€ Dataset/                   # DonnÃ©es d'entraÃ®nement
â”œâ”€â”€ models/                    # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ logs/                      # Logs et mÃ©triques
â”œâ”€â”€ train.py                   # Script d'entraÃ®nement
â”œâ”€â”€ run_api.py                 # Script de lancement API
â”œâ”€â”€ requirements.txt           # DÃ©pendances
â”œâ”€â”€ .env.example              # Variables d'environnement
â””â”€â”€ README.md                 # Documentation
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- CUDA 11.8+ (optionnel, pour GPU)
- 8GB+ RAM
- 4GB+ VRAM (pour entraÃ®nement GPU)

### Installation des dÃ©pendances

```bash
# Cloner le projet
git clone <repository-url>
cd "Projet 8 IA GÃ©nÃ©rative"

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Configuration

```bash
# Copier le fichier de configuration
cp .env.example .env

# Ã‰diter les variables d'environnement
# Ajuster les chemins selon votre configuration
```

## ğŸ“Š Dataset

Le projet utilise un dataset d'art situÃ© dans `Dataset/`. La structure attendue :

```
Dataset/
â”œâ”€â”€ artists.csv              # MÃ©tadonnÃ©es des artistes
â””â”€â”€ images/
    â”œâ”€â”€ artist1/
    â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â””â”€â”€ image2.jpg
    â””â”€â”€ artist2/
        â”œâ”€â”€ image1.jpg
        â””â”€â”€ image2.jpg
```

### Analyse du dataset

```bash
# Analyser le dataset avant l'entraÃ®nement
python train.py --analyze
```

## ğŸ“ EntraÃ®nement

### DCGAN (Deep Convolutional GAN)

```bash
# EntraÃ®nement basique
python train.py --model dcgan --epochs 100

# Avec paramÃ¨tres personnalisÃ©s
python train.py --model dcgan \
    --epochs 200 \
    --batch-size 32 \
    --learning-rate 0.0002 \
    --seed 42

# Avec arrÃªt prÃ©coce
python train.py --model dcgan \
    --epochs 500 \
    --early-stopping \
    --patience 20
```

### CycleGAN

```bash
# EntraÃ®nement CycleGAN
python train.py --model cyclegan --epochs 200
```

### Options d'entraÃ®nement

- `--model` : Type de modÃ¨le (`dcgan`, `cyclegan`)
- `--epochs` : Nombre d'Ã©poques
- `--batch-size` : Taille du batch
- `--learning-rate` : Taux d'apprentissage
- `--seed` : Graine alÃ©atoire
- `--early-stopping` : ArrÃªt prÃ©coce
- `--patience` : Patience pour l'arrÃªt prÃ©coce
- `--log-level` : Niveau de logging
- `--analyze` : Analyser le dataset

## ğŸŒ API

### Lancement de l'API

```bash
# Lancement basique
python run_api.py

# Avec paramÃ¨tres personnalisÃ©s
python run_api.py \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4

# Mode dÃ©veloppement
python run_api.py --reload --log-level DEBUG
```

### Endpoints disponibles

#### SantÃ© de l'API
```http
GET /health
```

#### Liste des modÃ¨les
```http
GET /models
```

#### GÃ©nÃ©ration d'images
```http
POST /generate
Content-Type: application/json

{
    "model_name": "dcgan_final",
    "num_images": 4,
    "seed": 42,
    "temperature": 1.0,
    "format": "png"
}
```

#### Interpolation dans l'espace latent
```http
POST /interpolate
Content-Type: application/json

{
    "model_name": "dcgan_final",
    "start_seed": 42,
    "end_seed": 123,
    "steps": 10,
    "interpolation_type": "linear"
}
```

#### Transfert de style (CycleGAN)
```http
POST /style-transfer
Content-Type: application/json

{
    "model_name": "cyclegan_final",
    "image_data": "base64_encoded_image",
    "direction": "A2B"
}
```

### Documentation interactive

Une fois l'API lancÃ©e, accÃ©dez Ã  :
- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

## ğŸ“ˆ Monitoring et MÃ©triques

### MÃ©triques d'Ã©valuation

- **FID (FrÃ©chet Inception Distance)** : QualitÃ© des images gÃ©nÃ©rÃ©es
- **IS (Inception Score)** : DiversitÃ© et qualitÃ©
- **LPIPS** : SimilaritÃ© perceptuelle
- **SSIM** : SimilaritÃ© structurelle

### Logs et visualisations

```bash
# Les logs sont sauvegardÃ©s dans logs/
logs/
â”œâ”€â”€ training_*.log           # Logs d'entraÃ®nement
â”œâ”€â”€ api_*.log               # Logs de l'API
â”œâ”€â”€ metrics.json            # MÃ©triques d'entraÃ®nement
â”œâ”€â”€ loss_plots.png          # Graphiques de perte
â””â”€â”€ generated_images/       # Images gÃ©nÃ©rÃ©es pendant l'entraÃ®nement
```

## ğŸ”§ Configuration avancÃ©e

### Variables d'environnement

```bash
# Chemins
PROJECT_ROOT=/path/to/project
DATASET_PATH=/path/to/dataset
MODELS_PATH=/path/to/models

# API
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# EntraÃ®nement
BATCH_SIZE=32
LEARNING_RATE=0.0002
EPOCHS=100

# GPU
CUDA_VISIBLE_DEVICES=0
```

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest

# Tests avec couverture
pytest --cov=src

# Tests spÃ©cifiques
pytest tests/test_models.py
pytest tests/test_api.py
```

## ğŸ“ Exemples d'utilisation

### GÃ©nÃ©ration d'images via Python

```python
import torch
from src.models import DCGAN
from src.api.utils import tensor_to_pil

# Charger le modÃ¨le
model = DCGAN.load_model("models/dcgan_final.pth")
model.eval()

# GÃ©nÃ©rer des images
with torch.no_grad():
    noise = torch.randn(4, 100, 1, 1)
    fake_images = model.generator(noise)
    
    # Convertir en PIL
    for i, tensor in enumerate(fake_images):
        image = tensor_to_pil(tensor)
        image.save(f"generated_{i}.png")
```

### Utilisation de l'API via curl

```bash
# GÃ©nÃ©rer des images
curl -X POST "http://localhost:8000/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "model_name": "dcgan_final",
       "num_images": 2,
       "seed": 42
     }'

# Interpolation
curl -X POST "http://localhost:8000/interpolate" \
     -H "Content-Type: application/json" \
     -d '{
       "model_name": "dcgan_final",
       "start_seed": 42,
       "end_seed": 123,
       "steps": 5
     }'
```

## ğŸ› DÃ©pannage

### Erreurs communes

**CUDA Out of Memory**
```bash
# RÃ©duire la taille du batch
python train.py --batch-size 16

# Ou utiliser le CPU
CUDA_VISIBLE_DEVICES="" python train.py
```

**Dataset non trouvÃ©**
```bash
# VÃ©rifier le chemin dans .env
echo $DATASET_PATH

# Ou spÃ©cifier explicitement
python train.py --dataset-path /path/to/dataset
```

**ModÃ¨le non chargÃ©**
```bash
# VÃ©rifier les modÃ¨les disponibles
ls models/

# VÃ©rifier les logs
tail -f logs/api_*.log
```

## ğŸ“š Ressources

### Papers de rÃ©fÃ©rence

- [DCGAN](https://arxiv.org/abs/1511.06434) - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks
- [CycleGAN](https://arxiv.org/abs/1703.10593) - Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
- [FID](https://arxiv.org/abs/1706.08500) - GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium

### Documentation

- [PyTorch](https://pytorch.org/docs/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Albumentations](https://albumentations.ai/docs/)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Cyril** - *DÃ©veloppement initial* - [BenLe302](https://github.com/BenLe302)

## ğŸ™ Remerciements

- Dataset d'art utilisÃ©
- CommunautÃ© PyTorch
- Papers de recherche en GANs
- Contributeurs open source